\documentclass[output=paper]{langsci/langscibook} 
\author{%
	Emily M.\ Bender\affiliation{University of Washington} \lastand
Guy Emerson\affiliation{Cambridge University}
}
\title{Computational linguistics and Language Engineering}

% \chapterDOI{} %will be filled in at production

%\epigram{Change epigram in chapters/03.tex or remove it there }
%\abstract{Change the  abstract in chapters/03.tex \lipsum[3]}
\maketitle

\begin{document}

% Comments from Gerald:

%I assume that the contributors would agree with me that this handbook is probably the wrong place to go into great technical detail on mathematical or computational subjects, but there needs to be at least something there to serve as a starting point from which the reader could choose to jump into some of the papers cited.‎ A summary of the major trends and the high-level intuitions behind a lot of the technical terminology that readers will encounter in HPSG-related CL papers, for example, would both be most welcome.

\section{Introduction}

% First draft: Emily

From the inception of HPSG in the joint work of Ivan Sag, Geoff Pullum, Tom Wasow, Mark Gawron, Carl Pollard and Dan Flickinger at HP Labs in the 1980s \cite{FIXME-CLobit-or-other}, there has been a close integration between theoretical and computational work. In this chapter, we give an overview of computational work in HPSG, starting with the infrastructure that supports it (both theoretical and practical) in \S\ref{sec:infrastructure}. Next we describe several existing large-scale projects which build HPSG or HPSG-inspired grammars (\S\ref{sec:resources}) and the deployment of such grammars in applications including both those within linguistic research and otherwise (\S\ref{sec:deployment}).  Finally, we turn to lessons for linguistics gleaned from broad-coverage grammar gdevelopment.

% EMB 2018-07-26 That seems like a relatively weak intro, but putting it in as aplace-holder for now. 
% EMB 2018-07-26 Also, I wonder if ``lessons for lingusitics'' might not come across as condescending...

\section{Infrastructure}
\label{sec:infrastructure}

% First draft: By subsection

\subsection{Theoretical considerations}

There are several properties of HPSG as a theory that make it well-suited to computational implementation. First, the theory is kept separate from the formalism: the formalism is expressive enough to encode a wide variety of possible theories. While some theoretical work does argue for or against the necessity of particular formal devices (e.g.\ the shuffle operator \cite{FIXME-Reape}), much of it proceeds within shared assumptions about the formalism. This is in contrast to work in the context of the Minimalist Program \cite{Chomsky93b-u}, where theoretical results are typically couched in terms of modifications to the formlism itself. From a computational point of view, the benefit of differentiating between theory and formalism is that it means that the formalism is relatively stable. That in turns enables the development and maintenance of software systems that target the formalism, for parsing, generation, and grammar exploration (see \S\ref{sec:history} below for some examples).\footnote{There are implementations of Minimalism, notably \cite{FIXME-Stabler} and \cite{FIXME-Indianadiss}. However, doing an implementation requires fixing the formalism, and so these are unlikely to be useful for testing theoretical ideas as the theory moves on.}

A second important property of HPSG that supports a strong connection between theoretical and computational work is an interest in both so-called `core' and so-called `peripheral' phenomena. Most implemented grammars are built with the goal of handling naturally occurring text.\footnote{Though it is possible to do implementation work strictly against testsuites of sentences constructed specifically to focus on phenomena of interest.} This means that they will need to handle a wide variety of linguistic phenomena not always treated in theoretical syntactic work \cite{FIXME-Baldwin-et-al-Beauty}. A syntactic framework that excludes research on `peripheral' phenomena as uninteresting provides less support for implementational work than does one, like HPSG or Construction Grammar \cite{FIXME}, that values such topics.

Finally, the type hierarchy characteristic of HPSG lends itself well to developing broad-coverage grammars which are maintainable over time \cite{FIXME-find-cite?}. The use of the type hierarchy to manage complexity at scale comes out of the work of Dan Flickinger \cite{Flickinger87} an others at HP labs in the project where HPSG was originally developed. The core idea is that any given constraint is (ideally) expressed only once on types which serve as supertypes to all entities that bear that constraint.\footnot{Originally this only applied to lexical entries in Flickinger's work. Now it also applies phrase structure rules, lexical rules, and types below the level of the sign which are used in the definition of all of these.} Such constraints might represent broad generalizations that apply to many entities or relatively narrow, indiosyncratic properties. By isolating any given constraint on one type (as opposed to repeating it in mutiple places), we build grammars that are easier to update and adapt in light of new data that require refinements to constraints. Having a single locus for each constraint also makes the types a very useful target for documentation \cite{FIXME:LTDB} and grammar exploration \cite{FIXME:typediff}. 


\subsection{Practical considerations}

Tractability / pratical considerations  % First draft: Guy

    \begin{itemize}
    \item Turing-completeness in theory
    \item Efficiency in practice
    \item Difference of perspective compared to CCG, TAG
    \item Parse ranking
    \end{itemize}

\subsection{A brief history of HPSG grammar engineering}
\label{sec:history}

History: PAGE, VerbMobil, ?? % First draft: Emily

Current platforms:
    \begin{itemize}
    \item LKB/ACE/PET/Agree
    \item Trale
    \item Other
    \end{itemize}


\section{Development of HPSG resources}
\label{sec:resources}

% First draft: DELPH-IN, Emily / non-DELPH-IN, Guy

\begin{itemize}
 \item  CoreGram
 \item  DELPH-IN consortium
    \begin{itemize}
    \item ERG
    \item Other large-ish grammars
    \item Grammar Matrix
    \end{itemize}
 \item Systems inspired by HPSG:
   \begin{itemize}
     \item Alpino
     \item Enju
     \item RASP
   \end{itemize}
\end{itemize}

% Alpino cites from Gertjan:

%% Gosse Bouma, Gertjan van Noord, Robert Malouf. Alpino: Wide Coverage Computational Analysis of Dutch. In: Computational Linguistics in the Netherlands CLIN 2000.

%% Leonoor van der Beek, Gosse Bouma, Gertjan van Noord. Een brede computationele grammatica voor het Nederlands. Nederlandse Taalkunde, jaargang 7, 2002-4. [in Dutch]. 353--374. 

%% Gertjan van Noord. At Last Parsing Is Now Operational. In: Piet Mertens, Cedrick Fairon, Anne Dister, Patrick Watrin (editors): TALN06. Verbum Ex Machina. Actes de la 13e conference sur le traitement automatique des langues naturelles. Page 20--42.

%% Gertjan van Noord. Self-trained Bilexical Preferences to Improve Disambiguation Accuracy. In: Harry Bunt, Paola Merlo and Joakim Nivre (editors), Trends in Parsing Technology. Dependency Parsing, Domain Adaptation, and Deep Parsing. Springer Verlag. pp 183-200. 2010.

%% Barbara Plank and Gertjan van Noord. Dutch Dependency Parser Performance Across Domains. In: Proceedings of the 20th Meeting of Computational Linguistics in the Netherlands. 

%% Daniël de Kok and Barbara Plank and Gertjan van Noord. Reversible Stochastic Attribute-value Grammars. In: ACL 2011.

%% Gertjan van Noord, Robert Malouf. Wide Coverage Parsing with Stochastic Attribute Value Grammars. Draft. Improved version of:

%% Robert Malouf, Gertjan van Noord. Wide Coverage Parsing with Stochastic Attribute Value Grammars. In: IJCNLP-04 Workshop Beyond Shallow Analyses - Formalisms and statistical modeling for deep analyses. 

%% all are available from http://www.let.rug.nl/vannoord/papers/

\section{Deployment of HPSG resources}
\label{sec:deployment}

% First draft: ...

\begin{itemize}
 \item Language documentation/linguistic hypothesis testing
    \begin{itemize}
    \item CoreGram % Guy
    \item Grammar Matrix % Emily
    \item AGGREGATION % Emily
    \end{itemize}
 \item DELPH-IN:
    \begin{itemize}
    \item DELPH-IN Applications: Things we do using DELPH-IN grammars directly % Guy
    \item Derived resources: Redwoods-style treebanks % Emily
    \item Training data for Deep Learning % Guy
    \end{itemize}
 \item Alpino % Guy
    \begin{itemize}
    \item ??
    \end{itemize}
 \item Other?
 \end{itemize}

\section{Lessons for Linguistics}
\begin{itemize}
    \item Ambiguity % Guy
    \item Long-tail phenomena (raising and control?) % Emily
    \item Scaling up (thematic roles) % Emily
    \item CLIMB methodology % Emily
\end{itemize}

\section{Summary}

\section*{Abbreviations}
\section*{Acknowledgements}

\printbibliography[heading=subbibliography,notkeyword=this] 
\end{document}
